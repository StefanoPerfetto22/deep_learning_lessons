{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion_mnist_train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neural1977/deep_learning_lessons/blob/master/fashion_mnist_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nuWAAx5x1nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# general imports\n",
        "import keras\n",
        "import numpy as np\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# keras imports\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import fashion_mnist, mnist\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "input_dim = 784\n",
        "default_callbacks = []\n",
        "random.seed(42)\n",
        "\n",
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "for k in range(1):\n",
        "    # Show the first image from the training set\n",
        "    plt.imshow(X_train[k], cmap = 'gray')\n",
        "    plt.savefig(\"first_fashion_mnist_train_image_\"+str(k)+\".jpg\")\n",
        "    print(\"First fashion mnist train image\", y_train[0])\n",
        "    plt.show(block = False)\n",
        "    plt.pause(3)\n",
        "    plt.close()\n",
        "\n",
        "for k in range(1):\n",
        "    # Show the first image from the test set\n",
        "    plt.imshow(X_test[k], cmap = 'gray')\n",
        "    plt.savefig(\"first_fashion_mnist_test_image\"+str(k)+\".jpg\")\n",
        "    print(\"First fashion mnist test image\", y_test[0])\n",
        "    plt.show(block = False)\n",
        "    plt.pause(3)\n",
        "    plt.close()\n",
        "    \n",
        "X_train = X_train.reshape(60000,784)                # linearization of image data (which is 2-dimensional originally) because our model is mlp, so accept only linear data, unlike convolutional networks\n",
        "X_test = X_test.reshape(10000,784)\n",
        "\n",
        "# Normalization (testare come senza normalizzazione converge molto tardi a 95% rispetto alla normalizzazione)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=input_dim))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "model.summary()\n",
        "\n",
        "#pdb.set_trace()\n",
        "\n",
        "# Convert labels to categorical one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "checkPoint=ModelCheckpoint(\"fm.cnn\", save_weights_only=True, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "default_callbacks = default_callbacks+[checkPoint]\n",
        "\n",
        "earlyStopping=EarlyStopping(monitor='val_loss', min_delta = 0.01, patience=5, verbose=0, mode='min') \n",
        "default_callbacks = default_callbacks+[earlyStopping]\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, y_train, validation_split = 0.2, epochs=10, batch_size=128, \n",
        "                                        callbacks = default_callbacks, verbose = 2)\n",
        "                                                                                \n",
        "#model.save_weights(\"fm.cnn\")\n",
        "\n",
        "model.load_weights(\"fm.cnn\")\n",
        "                                        \n",
        "score = model.evaluate(X_test, y_test, batch_size=5000)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}